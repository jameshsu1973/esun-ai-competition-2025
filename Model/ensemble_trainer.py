"""Ensemble æ¨¡å‹è¨“ç·´æ¨¡çµ„ - LightGBM + XGBoost + CatBoostã€‚

æ­¤æ¨¡çµ„å¯¦ä½œ Ensemble Learning æ–¹æ³•ï¼Œçµåˆä¸‰ç¨®æ¢¯åº¦æå‡æ¨¹æ¨¡å‹ï¼š
- LightGBM: åŸºæ–¼ Histogram çš„å¿«é€Ÿ GBDT
- XGBoost: ç¶“å…¸æ¢¯åº¦æå‡æ±ºç­–æ¨¹
- CatBoost: å°ˆæ³¨æ–¼é¡åˆ¥ç‰¹å¾µçš„ GBDT

è¨“ç·´æµç¨‹ï¼š
1. 5-Fold Stratified Cross-Validation
2. æ¯å€‹ fold è¨“ç·´ä¸‰å€‹æ¨¡å‹
3. æ”¶é›†é©—è­‰é›†é æ¸¬æ©Ÿç‡
4. æœç´¢æœ€ä½³é–¾å€¼ä»¥æœ€å¤§åŒ– F1 Score
5. è¼¸å‡ºç‰¹å¾µé‡è¦æ€§èˆ‡é–¾å€¼åˆ†æåœ–

Classes:
    EnsembleTrainer: Ensemble æ¨¡å‹è¨“ç·´å™¨ã€‚

Example:
    >>> from Model.ensemble_trainer import EnsembleTrainer
    >>> from Config.config import Config
    >>> trainer = EnsembleTrainer(Config)
    >>> trainer.train(df_train)
    >>> print(f"æœ€ä½³é–¾å€¼: {trainer.threshold:.4f}")
"""

import numpy as np
import pandas as pd
import lightgbm as lgb
import xgboost as xgb
from catboost import CatBoostClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix
from Config.config import Config
from Utils.evaluation import find_best_threshold
from Utils.visualization import plot_threshold_analysis

class EnsembleTrainer:
    """Ensemble æ¨¡å‹è¨“ç·´å™¨ - è¨“ç·´ä¸¦ç®¡ç†ä¸‰ç¨® GBDT æ¨¡å‹ã€‚
    
    æ­¤é¡åˆ¥è² è²¬å®Œæ•´çš„ Ensemble è¨“ç·´æµç¨‹ï¼ŒåŒ…å«ï¼š
    - ç‰¹å¾µæ¨™æº–åŒ–
    - 5-Fold Stratified Cross-Validation
    - è¨“ç·´ LightGBMã€XGBoostã€CatBoost
    - è‡ªå‹•é–¾å€¼æœç´¢
    - ç‰¹å¾µé‡è¦æ€§åˆ†æ
    
    Attributes:
        config: é…ç½®ç‰©ä»¶ï¼ˆé è¨­ç‚º Configï¼‰ã€‚
        models (dict): æ¨¡å‹å­—å…¸ï¼Œæ ¼å¼ç‚º {'lgb': [...], 'xgb': [...], 'cat': [...]},
            æ¯å€‹ list åŒ…å« 5 å€‹ fold çš„æ¨¡å‹ã€‚
        scaler (StandardScaler): ç‰¹å¾µæ¨™æº–åŒ–å™¨ã€‚
        threshold (float): æœ€ä½³é æ¸¬é–¾å€¼ã€‚
        feature_cols (list): ç‰¹å¾µæ¬„ä½åç¨±æ¸…å–®ã€‚
        feature_importance (pd.DataFrame): ç‰¹å¾µé‡è¦æ€§æ’åºã€‚
    
    Example:
        >>> trainer = EnsembleTrainer()
        >>> trainer.train(df_train)
        >>> print(f"è¨“ç·´äº† {len(trainer.models['lgb'])} å€‹ LightGBM æ¨¡å‹")
        5
    """
    
    def __init__(self, config=None):
        """åˆå§‹åŒ– Ensemble è¨“ç·´å™¨ã€‚
        
        Args:
            config: é…ç½®ç‰©ä»¶ï¼ŒåŒ…å«è¶…åƒæ•¸ã€äº¤å‰é©—è­‰è¨­å®šç­‰ã€‚
                è‹¥æœªæŒ‡å®šå‰‡ä½¿ç”¨ Config é¡åˆ¥ã€‚
        """
        self.config = config or Config
        self.models = {'lgb': [], 'xgb': [], 'cat': []}
        self.scaler = None
        self.threshold = 0.5
        self.feature_cols = None
        self.feature_importance = None
    
    def train(self, df_train):
        """è¨“ç·´ Ensemble æ¨¡å‹ä¸¦æœç´¢æœ€ä½³é–¾å€¼ã€‚
        
        å®Œæ•´è¨“ç·´æµç¨‹ï¼š
        1. æº–å‚™ç‰¹å¾µï¼šæå–ç‰¹å¾µæ¬„ä½ï¼Œè™•ç†ç¼ºå¤±å€¼å’Œç„¡çª®å€¼
        2. ç‰¹å¾µæ¨™æº–åŒ–ï¼šä½¿ç”¨ StandardScaler
        3. äº¤å‰é©—è­‰ï¼š5-Fold Stratified CV
        4. æ¨¡å‹è¨“ç·´ï¼šæ¯å€‹ fold è¨“ç·´ LightGBMã€XGBoostã€CatBoost
        5. é–¾å€¼æœç´¢ï¼šåœ¨é©—è­‰é›†ä¸Šæœç´¢æœ€ä½³ F1 é–¾å€¼ï¼ˆ0.1-0.9ï¼‰
        6. è¦–è¦ºåŒ–ï¼šç¹ªè£½é–¾å€¼åˆ†æåœ–
        7. ç‰¹å¾µé‡è¦æ€§ï¼šè¼¸å‡º Top 15 é‡è¦ç‰¹å¾µ
        
        Args:
            df_train (pd.DataFrame): è¨“ç·´è³‡æ–™ï¼Œéœ€åŒ…å«ï¼š
                - acct: å¸³æˆ¶ ID
                - label: æ¨™ç±¤ï¼ˆ1=è­¦ç¤º, 0=æ­£å¸¸ï¼‰
                - 62 å€‹ç‰¹å¾µæ¬„ä½
        
        Side Effects:
            - æ›´æ–° self.modelsï¼ˆ15 å€‹æ¨¡å‹ï¼š3 é¡å‹ Ã— 5 foldsï¼‰
            - æ›´æ–° self.scalerï¼ˆæ¨™æº–åŒ–å™¨ï¼‰
            - æ›´æ–° self.thresholdï¼ˆæœ€ä½³é–¾å€¼ï¼‰
            - æ›´æ–° self.feature_colsï¼ˆç‰¹å¾µåç¨±ï¼‰
            - æ›´æ–° self.feature_importanceï¼ˆç‰¹å¾µé‡è¦æ€§ï¼‰
            - å„²å­˜ threshold_analysis.pngï¼ˆé–¾å€¼åˆ†æåœ–ï¼‰
        
        Example:
            >>> trainer = EnsembleTrainer()
            >>> trainer.train(df_train)
            ğŸš€ [æ¨¡å‹è¨“ç·´] Ensemble æ¨¡å‹ (5-Fold CV)
            ...
            ğŸ¯ æœ€ä½³é–¾å€¼: 0.5300
        """
        print("="*70)
        print(f"ğŸš€ [æ¨¡å‹è¨“ç·´] Ensemble æ¨¡å‹ ({self.config.N_SPLITS}-Fold CV)")
        
        feature_cols = [c for c in df_train.columns if c not in ['acct', 'label']]
        X = df_train[feature_cols].fillna(0).replace([np.inf, -np.inf], 0)
        y = df_train['label']
        
        print(f"ç‰¹å¾µæ•¸: {len(feature_cols)}, æ¨£æœ¬æ•¸: {len(X)}")
        
        # æ¨™æº–åŒ–
        self.scaler = StandardScaler()
        X_scaled = self.scaler.fit_transform(X)
        X_scaled = pd.DataFrame(X_scaled, columns=feature_cols, index=X.index)
        
        # äº¤å‰é©—è­‰
        skf = StratifiedKFold(
            n_splits=self.config.N_SPLITS, 
            shuffle=True, 
            random_state=self.config.RANDOM_SEED
        )
        
        all_val_probs = []
        all_val_labels = []
        
        for fold, (train_idx, val_idx) in enumerate(skf.split(X_scaled, y)):
            print(f"\n--- Fold {fold+1}/{self.config.N_SPLITS} ---")
            
            X_tr, X_val = X_scaled.iloc[train_idx], X_scaled.iloc[val_idx]
            y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]
            
            pos_weight = (y_tr == 0).sum() / max((y_tr == 1).sum(), 1)
            print(f"è¨“ç·´:{len(X_tr):,} (è­¦ç¤º:{y_tr.sum()}), é©—è­‰:{len(X_val):,} (è­¦ç¤º:{y_val.sum()})")
            
            # è¨“ç·´ä¸‰å€‹æ¨¡å‹
            lgb_model = self._train_lightgbm(X_tr, y_tr, pos_weight)
            xgb_model = self._train_xgboost(X_tr, y_tr, pos_weight)
            cat_model = self._train_catboost(X_tr, y_tr, pos_weight)
            
            self.models['lgb'].append(lgb_model)
            self.models['xgb'].append(xgb_model)
            self.models['cat'].append(cat_model)
            
            # Ensemble é æ¸¬
            lgb_probs = lgb_model.predict_proba(X_val)[:, 1]
            xgb_probs = xgb_model.predict_proba(X_val)[:, 1]
            cat_probs = cat_model.predict_proba(X_val)[:, 1]
            avg_probs = (lgb_probs + xgb_probs + cat_probs) / 3
            
            all_val_probs.extend(avg_probs)
            all_val_labels.extend(y_val)
        
        # å°‹æ‰¾æœ€ä½³é–¾å€¼
        print("\n" + "="*70)
        print("ğŸ” å°‹æ‰¾æœ€ä½³é–¾å€¼...")
        
        all_val_probs = np.array(all_val_probs)
        all_val_labels = np.array(all_val_labels)
        
        best_threshold, best_f1, threshold_results = find_best_threshold(
            all_val_labels, all_val_probs,
            threshold_min=self.config.THRESHOLD_MIN,
            threshold_max=self.config.THRESHOLD_MAX,
            threshold_step=self.config.THRESHOLD_STEP
        )
        
        print(f"\nğŸ¯ æœ€ä½³é–¾å€¼: {best_threshold:.4f}")
        print(f"   å°æ‡‰ F1: {best_f1:.4f}")
        print(f"   Precision: {threshold_results[best_threshold]['precision']:.4f}")
        print(f"   Recall: {threshold_results[best_threshold]['recall']:.4f}")
        
        pred_count = np.sum(all_val_probs >= best_threshold)
        print(f"   é©—è­‰é›†é æ¸¬è­¦ç¤º: {pred_count}/{len(all_val_labels)} ({pred_count/len(all_val_labels):.2%})")
        
        self.threshold = best_threshold
        self.feature_cols = feature_cols
        
        # ç¹ªè£½é–¾å€¼åˆ†æåœ–
        plot_threshold_analysis(threshold_results, best_threshold)
        
        # ç‰¹å¾µé‡è¦æ€§
        self._print_feature_importance(feature_cols)
    
    def _train_lightgbm(self, X, y, pos_weight):
        """è¨“ç·´ LightGBM æ¨¡å‹ã€‚
        
        Args:
            X (pd.DataFrame): ç‰¹å¾µçŸ©é™£ï¼ˆå·²æ¨™æº–åŒ–ï¼‰ã€‚
            y (pd.Series): æ¨™ç±¤å‘é‡ã€‚
            pos_weight (float): æ­£æ¨£æœ¬æ¬Šé‡ï¼Œç”¨æ–¼è™•ç†é¡åˆ¥ä¸å¹³è¡¡ã€‚
        
        Returns:
            lgb.LGBMClassifier: è¨“ç·´å¥½çš„ LightGBM æ¨¡å‹ã€‚
        """
        params = self.config.LGBM_PARAMS.copy()
        params['scale_pos_weight'] = pos_weight
        model = lgb.LGBMClassifier(**params)
        model.fit(X, y)
        return model
    
    def _train_xgboost(self, X, y, pos_weight):
        """è¨“ç·´ XGBoost æ¨¡å‹ã€‚
        
        Args:
            X (pd.DataFrame): ç‰¹å¾µçŸ©é™£ï¼ˆå·²æ¨™æº–åŒ–ï¼‰ã€‚
            y (pd.Series): æ¨™ç±¤å‘é‡ã€‚
            pos_weight (float): æ­£æ¨£æœ¬æ¬Šé‡ï¼Œç”¨æ–¼è™•ç†é¡åˆ¥ä¸å¹³è¡¡ã€‚
        
        Returns:
            xgb.XGBClassifier: è¨“ç·´å¥½çš„ XGBoost æ¨¡å‹ã€‚
        """
        params = self.config.XGB_PARAMS.copy()
        params['scale_pos_weight'] = pos_weight
        model = xgb.XGBClassifier(**params)
        model.fit(X, y)
        return model
    
    def _train_catboost(self, X, y, pos_weight):
        """è¨“ç·´ CatBoost æ¨¡å‹ã€‚
        
        Args:
            X (pd.DataFrame): ç‰¹å¾µçŸ©é™£ï¼ˆå·²æ¨™æº–åŒ–ï¼‰ã€‚
            y (pd.Series): æ¨™ç±¤å‘é‡ã€‚
            pos_weight (float): æ­£æ¨£æœ¬æ¬Šé‡ï¼Œç”¨æ–¼è™•ç†é¡åˆ¥ä¸å¹³è¡¡ã€‚
        
        Returns:
            CatBoostClassifier: è¨“ç·´å¥½çš„ CatBoost æ¨¡å‹ã€‚
        """
        params = self.config.CAT_PARAMS.copy()
        params['scale_pos_weight'] = pos_weight
        model = CatBoostClassifier(**params)
        model.fit(X, y)
        return model
    
    def _print_feature_importance(self, feature_cols):
        """è¼¸å‡º Top 15 ç‰¹å¾µé‡è¦æ€§ï¼ˆåŸºæ–¼ LightGBMï¼‰ã€‚
        
        ä½¿ç”¨ç¬¬ä¸€å€‹ fold çš„ LightGBM æ¨¡å‹è¨ˆç®—ç‰¹å¾µé‡è¦æ€§ï¼Œ
        ä¸¦ä»¥ DataFrame æ ¼å¼å„²å­˜è‡³ self.feature_importanceã€‚
        
        Args:
            feature_cols (list): ç‰¹å¾µæ¬„ä½åç¨±æ¸…å–®ã€‚
        
        Side Effects:
            - æ›´æ–° self.feature_importance
            - è¼¸å‡º Top 15 ç‰¹å¾µåˆ° console
        """
        print("\nğŸ† Top 15 é‡è¦ç‰¹å¾µ (LightGBM):")
        self.feature_importance = pd.DataFrame({
            'feature': feature_cols,
            'importance': self.models['lgb'][0].feature_importances_
        }).sort_values('importance', ascending=False)
        
        for i, row in self.feature_importance.head(15).iterrows():
            print(f"  {row['feature']:30s}: {row['importance']:.1f}")
